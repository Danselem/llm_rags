{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDkxcR-Snp0b"
      },
      "source": [
        "# SQL Query Generator ðŸ¤–ðŸ§‘ðŸ»â€ðŸ’»\n",
        "This notebook demonstrates the ability to generate SQL queries from a given natural language question. The notebook is divided into two parts:\n",
        "1. **Data Generation**: This section generates fake CRM data and stores it in a SQL database.\n",
        "2. **Query Generation**: This section generates SQL queries from natural language questions.\n",
        "\n",
        "## Data Generation\n",
        "The following code generates fake CRM data for a second hand car market and stores it in a SQL database. The data is generated using the [Faker](https://faker.readthedocs.io/en/master/) library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI3ZhLxbp2jR",
        "outputId": "0220165e-4b2c-4984-ad11-79e6ead6a451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/162.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.2/162.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.4/162.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U --quiet langchain-google-genai pillow faker faker_vehicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "79994b6168374daaaa40d9206e4efede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 106,
        "execution_start": 1684266200758,
        "id": "PR7NsBpCnp0f",
        "outputId": "6582f1c6-6591-4e22-b0f1-51e42e1e75e4",
        "source_hash": "5ef407a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from faker import Faker\n",
        "from faker_vehicle import VehicleProvider\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "import os\n",
        "import psycopg2\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "dotenv_path = Path('./.env')\n",
        "load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "# server = os.environ['SQL_DATABASE_HOST']\n",
        "# database = os.environ['SQL_DATABASE_NAME']\n",
        "# username = os.environ['SQL_DATABASE_USER']\n",
        "# password = os.environ['SQL_DATABASE_PWD']\n",
        "# driver = '{ODBC Driver 17 for SQL Server}'\n",
        "\n",
        "# Create a connection string\n",
        "# connection_string = f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
        "\n",
        "# # use sqlalchemy to create a connection to the database\n",
        "# engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={connection_string}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "hostname = os.environ['SQL_DATABASE_HOST']\n",
        "database = os.environ['SQL_DATABASE_NAME']\n",
        "username = os.environ['SQL_DATABASE_USER']\n",
        "password = os.environ['SQL_DATABASE_PWD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'postgresql+psycopg2://postgres:delegiwa@localhost/postgres'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"postgresql+psycopg2://{}:{}@{}/{}\".format(username, password, hostname, database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "engine = create_engine('postgresql+psycopg2://{}:{}\\\n",
        "@{}/{}'.format(username, password, hostname, database))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = psycopg2.connect(database = database, \n",
        "                        user = username, \n",
        "                        host= server,\n",
        "                        password = password,\n",
        "                        port = 5432)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cell_id": "07ba78e112f14dfebca60cc5532edaf0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 6077,
        "execution_start": 1684260786032,
        "id": "wqV4XT09np0g",
        "source_hash": "19b5321e"
      },
      "outputs": [],
      "source": [
        "# Create a Faker instance for Belgium\n",
        "fake = Faker('nl_BE')\n",
        "fake.add_provider(VehicleProvider)\n",
        "\n",
        "def generate_customer_data(n):\n",
        "    \"\"\"Generate n rows of fake customer data.\"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        data.append([fake.unique.random_number(digits=5),\n",
        "                     fake.first_name(),\n",
        "                     fake.last_name(),\n",
        "                     fake.email(),\n",
        "                     fake.phone_number(),\n",
        "                     fake.street_address(),\n",
        "                     fake.city(),\n",
        "                     fake.postcode(),\n",
        "                     'Belgium'])\n",
        "    return data\n",
        "\n",
        "\n",
        "# Generate 10K rows of data\n",
        "data = generate_customer_data(10000)\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=['CustomerID', 'FirstName', 'LastName', 'Email', 'PhoneNumber', 'Address', 'City', 'PostalCode', 'Country'])\n",
        "\n",
        "# Save the data from dataframe to SQL Server, create a connection to the database\n",
        "with engine.connect() as conn:\n",
        "    df.to_sql('customers', conn, if_exists='replace', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7sFkdzf-np0h"
      },
      "outputs": [],
      "source": [
        "# Now let's generate a table of 100 cars: productID, brand, model, year, price\n",
        "fake.unique.clear()\n",
        "def generate_product_data(n):\n",
        "    \"\"\"Generate n rows of fake product data.\"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        vehicle = fake.vehicle_object()\n",
        "        data.append([fake.unique.random_number(digits=5),\n",
        "                     vehicle['Make'],\n",
        "                     vehicle['Model'],\n",
        "                     vehicle['Year'],\n",
        "                     fake.pydecimal(left_digits=5, right_digits=2, positive=True, min_value=100, max_value=10000)])\n",
        "    return data\n",
        "\n",
        "# Generate 100 rows of data\n",
        "data = generate_product_data(100)\n",
        "\n",
        "# Store in the database\n",
        "df = pd.DataFrame(data, columns=['ProductID', 'Brand', 'Model', 'Year', 'Price'])\n",
        "with engine.connect() as conn:\n",
        "    df.to_sql('cars', conn, if_exists='replace', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uszV9sCSnp0h"
      },
      "outputs": [],
      "source": [
        "# Now let's finally generate a table of 100K carsales data: SalesID, CustomerID, ProductID, Quantity, Price, DiscountPercent, Total, SalesAgent, Date\n",
        "fake.unique.clear()\n",
        "\n",
        "\n",
        "def generate_sales_data(n):\n",
        "    \"\"\"Generate n rows of fake sales data.\"\"\"\n",
        "    cars = pd.read_sql('SELECT \"ProductID\", \"Price\" FROM cars', engine)\n",
        "    customer_ids = pd.read_sql('SELECT \"CustomerID\" FROM customers', engine)\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        car = cars.sample().iloc[0]\n",
        "        quantity = fake.random_int(min=1, max=10)\n",
        "        discount = fake.random_int(min=0, max=10)\n",
        "        data.append([fake.unique.random_number(digits=5),\n",
        "                     customer_ids.sample().iloc[0]['CustomerID'],\n",
        "                     car['ProductID'],\n",
        "                     quantity,\n",
        "                     car['Price'],\n",
        "                     fake.random_int(min=0, max=10),\n",
        "                     float(car['Price']) * quantity * (1 - discount/100),\n",
        "                     fake.name(),\n",
        "                     fake.date_between(start_date='-1y', end_date='today')])\n",
        "    return data\n",
        "\n",
        "# Generate 10K rows of data\n",
        "data = generate_sales_data(10000)\n",
        "\n",
        "# Store in the database\n",
        "df = pd.DataFrame(data, columns=['SalesID', 'CustomerID', 'ProductID', 'Quantity', 'Price', 'DiscountPercent', 'Total', 'SalesAgent', 'Date'])\n",
        "with engine.connect() as conn:\n",
        "    df.to_sql('carsales', conn, if_exists='replace', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yjepxN9np0i"
      },
      "source": [
        "### Let's write some SQL queries to get some insights from the data\n",
        "After this we will use langchain to visualize the data and generate SQL queries from natural language questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dAEVyuZDnp0i",
        "outputId": "2a75efda-8258-4a5e-e3f4-0094f05c1967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    |   CustomerID | FirstName   | LastName   | Email                       | PhoneNumber      | Address          | City      |   PostalCode | Country   |\n",
            "|---:|-------------:|:------------|:-----------|:----------------------------|:-----------------|:-----------------|:----------|-------------:|:----------|\n",
            "|  0 |        48537 | Pieter      | Kenis      | lewis34@example.com         | +32244-826629    | Irenalaan 09     | Vlissegem |         8289 | Belgium   |\n",
            "|  1 |        18792 | Bert        | De Jonghe  | iclaeys@example.com         | +32(0)60-0640157 | Benboulevard 40  | Moorslede |         2596 | Belgium   |\n",
            "|  2 |        49318 | Anne        | Callens    | lennertbogaerts@example.net | +32(0)45 0845742 | Nataschalei 918  | Huccorgne |         9021 | Belgium   |\n",
            "|  3 |        55619 | Magdalena   | Dobbelaere | emilia25@example.net        | 0187 155278      | Anne-Mariepad 81 | Hees      |         1780 | Belgium   |\n",
            "|  4 |        63064 | Philippe    | Simons     | leen69@example.com          | 0138 679128      | Jeroensteeg 602  | Wasseiges |         3518 | Belgium   |\n"
          ]
        }
      ],
      "source": [
        "conn = engine.connect()\n",
        "# Display the first 5 rows of the customers table\n",
        "print(pd.read_sql('SELECT * FROM customers LIMIT 5', conn).to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ma7oreeanp0j",
        "outputId": "47669206-34c3-4dc6-f4d6-c5a7ceacc968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    |   ProductID | Brand   | Model    |   Year |   Price |\n",
            "|---:|------------:|:--------|:---------|-------:|--------:|\n",
            "|  0 |       85506 | MAZDA   | MAZDA3   |   2007 | 2051.3  |\n",
            "|  1 |       10876 | Jeep    | Cherokee |   1994 | 3019.24 |\n",
            "|  2 |       82092 | Honda   | Accord   |   2011 | 1689.58 |\n",
            "|  3 |       90797 | Audi    | S8       |   2001 | 4719.43 |\n",
            "|  4 |        8633 | Isuzu   | Ascender |   2004 | 8608.2  |\n"
          ]
        }
      ],
      "source": [
        "print(pd.read_sql('SELECT * FROM cars LIMIT 5', conn).to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qOcjEchQnp0k",
        "outputId": "69370574-ea18-4899-f288-eed5a020a1ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    |   SalesID |   CustomerID |   ProductID |   Quantity |   Price |   DiscountPercent |    Total | SalesAgent              | Date       |\n",
            "|---:|----------:|-------------:|------------:|-----------:|--------:|------------------:|---------:|:------------------------|:-----------|\n",
            "|  0 |     73498 |        76295 |       20191 |          4 | 7577.78 |                 0 | 30311.1  | Myriam Smets            | 2023-06-03 |\n",
            "|  1 |     77424 |         7530 |       63376 |          2 | 3848.96 |                 3 |  7543.96 | Jeannine De Waele       | 2023-12-08 |\n",
            "|  2 |     93067 |        24844 |       60800 |          4 | 9464.22 |                 0 | 36721.2  | Fatiha Geudens          | 2023-01-29 |\n",
            "|  3 |     76742 |        41651 |       24650 |          7 | 6999.57 |                 6 | 46057.2  | Thibaut Van Poucke Nijs | 2023-12-03 |\n",
            "|  4 |     78387 |        67157 |       65914 |          2 | 4797.52 |                 1 |  8827.44 | Noah Rottiers           | 2023-08-23 |\n"
          ]
        }
      ],
      "source": [
        "# Display the first 5 rows of the sales table\n",
        "conn = engine.connect()\n",
        "print(pd.read_sql('SELECT * FROM carsales LIMIT 5', conn).to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SiGn6G-tnp0k",
        "outputId": "7e51fcb5-58f0-4c30-becd-6bd753921226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most expensive car:\n",
            "   ProductID     Brand    Model  Year    Price\n",
            "0      26857  Cadillac  DeVille  1995  9773.63\n",
            "\n",
            "City with most sales:\n",
            "     City      revenue\n",
            "0  Idegem  592717.0273\n",
            "\n",
            "Best sales agent:\n",
            "     SalesAgent     revenue\n",
            "0  Luc Janssens  136917.093\n",
            "\n",
            "Most popular car:\n",
            "   Brand               Model  quantity\n",
            "0  Isuzu  i-290 Extended Cab    1302.0\n"
          ]
        }
      ],
      "source": [
        "with engine.connect() as conn:\n",
        "   # What is the most expensive car?\n",
        "   print('Most expensive car:')\n",
        "   print(pd.read_sql('SELECT * FROM cars ORDER BY \"Price\" DESC', conn).head(1))\n",
        "\n",
        "   # What city has the most sales renenue?\n",
        "   print('\\nCity with most sales:')\n",
        "   query = '''\n",
        "   SELECT \"City\", SUM(\"Total\") AS Revenue\n",
        "      FROM carsales\n",
        "      INNER JOIN customers ON carsales.\"CustomerID\" = customers.\"CustomerID\"\n",
        "      GROUP BY \"City\"\n",
        "      ORDER BY Revenue DESC\n",
        "      LIMIT 1;\n",
        "   '''\n",
        "   print(pd.read_sql(query, conn).head(1))\n",
        "\n",
        "   # Who is the best sales agent?\n",
        "   print('\\nBest sales agent:')\n",
        "   query = '''\n",
        "   SELECT \"SalesAgent\", SUM(\"Total\") AS Revenue\n",
        "      FROM carsales\n",
        "      GROUP BY \"SalesAgent\"\n",
        "      ORDER BY Revenue DESC;\n",
        "\n",
        "   '''\n",
        "   print(pd.read_sql(query, conn).head(1))\n",
        "\n",
        "   # What is the most popular car?\n",
        "   print('\\nMost popular car:')\n",
        "   query = '''\n",
        "   SELECT \"Brand\", \"Model\", SUM(\"Quantity\") AS Quantity\n",
        "      FROM carsales\n",
        "      INNER JOIN cars ON carsales.\"ProductID\" = cars.\"ProductID\"\n",
        "      GROUP BY \"Brand\", \"Model\"\n",
        "      ORDER BY Quantity DESC;\n",
        "\n",
        "   '''\n",
        "   print(pd.read_sql(query, conn).head(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hpLcjAinp0l"
      },
      "source": [
        "## Now let's use GPT to generate SQL queries from natural language questions â¬‡ï¸\n",
        "To make this work we do some things:\n",
        "1. We first check the database and find all the tables\n",
        "2. Then the system fetches 5 random rows from each table\n",
        "3. Then we use GPT to generate SQL queries from natural language questions, passing the table details and the rows as context\n",
        "4. Optionaly we add a function to parse the result and return it back in natual language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEWHG3I-np0l"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "dotenv_path = Path('./.env')\n",
        "load_dotenv(dotenv_path=dotenv_path) \n",
        "os.getenv(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Yes')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
        "model(\n",
        "    [\n",
        "        SystemMessage(content=\"Answer only yes or no.\"),\n",
        "        HumanMessage(content=\"Is apple a fruit?\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'TABLE_NAME'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/mlops/llm_rags/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TABLE_NAME'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Call get_random_rows() for each table, and store the results as markdown in a list\u001b[39;00m\n\u001b[1;32m     20\u001b[0m markdown \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_table_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     22\u001b[0m     markdown\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m### \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     markdown\u001b[38;5;241m.\u001b[39mappend(get_random_rows(table)\u001b[38;5;241m.\u001b[39mto_markdown())\n",
            "Cell \u001b[0;32mIn[29], line 9\u001b[0m, in \u001b[0;36mget_table_names\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      4\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    SELECT TABLE_NAME\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    FROM INFORMATION_SCHEMA.TABLES\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    WHERE TABLE_TYPE = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBASE TABLE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AND TABLE_CATALOG=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectrix-demo\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTABLE_NAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
            "File \u001b[0;32m~/mlops/llm_rags/.venv/lib/python3.9/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/mlops/llm_rags/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TABLE_NAME'"
          ]
        }
      ],
      "source": [
        "# Return the table names in the database\n",
        "def get_table_names():\n",
        "    with engine.connect() as conn:\n",
        "        query = '''\n",
        "        SELECT TABLE_NAME\n",
        "        FROM INFORMATION_SCHEMA.TABLES\n",
        "        WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_CATALOG='vectrix-demo'\n",
        "        '''\n",
        "        return pd.read_sql(query, conn)['TABLE_NAME'].tolist()\n",
        "\n",
        "\n",
        "# Get 5 random rows from a table and store them in a dataframe\n",
        "def get_random_rows(table, n=5):\n",
        "    with engine.connect() as conn:\n",
        "        query = f'SELECT * FROM {table} ORDER BY NEWID() LIMIT {n} '\n",
        "        return pd.read_sql(query, conn)\n",
        "\n",
        "\n",
        "# Call get_random_rows() for each table, and store the results as markdown in a list\n",
        "markdown = []\n",
        "for table in get_table_names():\n",
        "    markdown.append(f'### {table}')\n",
        "    markdown.append(get_random_rows(table).to_markdown())\n",
        "    markdown.append('\\n')\n",
        "\n",
        "# Join the markdown list into a single string\n",
        "table_definitions = '\\n'.join(markdown)\n",
        "table_definitions = table_definitions + '\\n---\\nReturn the TSQL Query for:'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoyiCdyMnp0l"
      },
      "outputs": [],
      "source": [
        "# Return the table names in the database\n",
        "def get_table_names():\n",
        "    with engine.connect() as conn:\n",
        "        query = '''\n",
        "        SELECT TABLE_NAME\n",
        "        FROM INFORMATION_SCHEMA.TABLES\n",
        "        WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_CATALOG='vectrix-demo'\n",
        "        '''\n",
        "        return pd.read_sql(query, conn)['TABLE_NAME'].tolist()\n",
        "\n",
        "\n",
        "# Get 5 random rows from a table and store them in a dataframe\n",
        "def get_random_rows(table, n=5):\n",
        "    with engine.connect() as conn:\n",
        "        query = f'SELECT * FROM {table} ORDER BY NEWID() LIMIT {n} '\n",
        "        return pd.read_sql(query, conn)\n",
        "\n",
        "\n",
        "# Call get_random_rows() for each table, and store the results as markdown in a list\n",
        "markdown = []\n",
        "for table in get_table_names():\n",
        "    markdown.append(f'### {table}')\n",
        "    markdown.append(get_random_rows(table).to_markdown())\n",
        "    markdown.append('\\n')\n",
        "\n",
        "# Join the markdown list into a single string\n",
        "table_definitions = '\\n'.join(markdown)\n",
        "table_definitions = table_definitions + '\\n---\\nReturn the TSQL Query for:'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4PpFU5enp0l"
      },
      "outputs": [],
      "source": [
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "\n",
        "def generate_query(prompt: str, table_definitions: str):\n",
        "    \"\"\"Answers a query using GPT\"\"\"\n",
        "    system = \"You are an SQL generator that only returns TSQL sequel statements and no natural language. Given the table names, definitions and a prompt.\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": table_definitions+prompt}\n",
        "    ]\n",
        "    #print(messages)\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=GPT_MODEL,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    #print(response_message)\n",
        "\n",
        "    return response_message\n",
        "\n",
        "def parse_result_in_natural_language(prompt: str, result: str):\n",
        "    '''\n",
        "    Parses the result of a query into natural language\n",
        "    '''\n",
        "    completion = prompt + '\\n' + result\n",
        "    messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"You transalte the result of a query and a prompt into natural language.\"},\n",
        "        {\"role\": \"user\", \"content\": completion}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=GPT_MODEL,\n",
        "        messages = messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "def run_query(prompt: str, return_natural_language: bool = False):\n",
        "    query = generate_query(prompt, table_definitions)\n",
        "    with engine.connect() as conn:\n",
        "        result =  pd.read_sql(query, conn).to_markdown()\n",
        "\n",
        "    if return_natural_language:\n",
        "        result = parse_result_in_natural_language(prompt, result)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPRQycShnp0m"
      },
      "source": [
        "## Let's try it out ðŸ¤—\n",
        "As you can see, when setting the function return_result to True, the system returns the result in natural language. This is done by parsing the result and replacing the column names with the column names in the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifNt4GrWnp0m",
        "outputId": "844621be-a96c-48fd-ccab-875f34899f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most expensive car in the given data is an Audi A8 from the year 1997, which costs 9849.09.\n"
          ]
        }
      ],
      "source": [
        "print(run_query('What is the most expensive car?', return_natural_language=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8aG21oynp0m",
        "outputId": "3286c620-c651-455e-bfde-8737c7f99e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    | City     |   TotalRevenue |\n",
            "|---:|:---------|---------------:|\n",
            "|  0 | Houwaart |         638551 |\n"
          ]
        }
      ],
      "source": [
        "print(run_query('What city has the most sales revenue?'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhcVHJVhnp0m",
        "outputId": "e1716e77-7970-4ccc-a473-a8fd782e1633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best sales agent is Bart Peeters.\n"
          ]
        }
      ],
      "source": [
        "print(run_query('Who is the best sales agent ?', return_natural_language=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovoXfibfnp0m",
        "outputId": "0826ed3a-fced-409d-8642-b3eed15073f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    | Brand   | Model                   |   TotalQuantity |\n",
            "|---:|:--------|:------------------------|----------------:|\n",
            "|  0 | Dodge   | Grand Caravan Passenger |            1695 |\n"
          ]
        }
      ],
      "source": [
        "print(run_query('What is the most popular car?'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "904895a1f7984c57b0abe32f19bd104e",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
